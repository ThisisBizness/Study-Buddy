---
description: 
globs: 
alwaysApply: true
---
**1. Project Overview**

You are tasked with building a focused, single-page web application called "STEM Helper". This tool will assist students by solving STEM problems submitted via text or image. It leverages the Google Gemini 2.5 Pro Experimental LLM (`gemini-2.5-pro-exp-03-25`) to provide not only the step-by-step solution but also a simple explanation of the underlying concepts and two relevant practice problems. The application will feature a chat-like interface displaying the session history (cleared on page reload). There is **no requirement for user accounts, login, or persistent data storage**.

**2. Agent Personality & Development Mindset**

* **Precision & Thoroughness:** Implement all requirements accurately. Ensure robust handling of inputs (text/image) and API responses.
* **Simplicity & Maintainability:** Prefer clear, straightforward code. Avoid unnecessary complexity. The explanation generated by the LLM must be *simple* and easy for a student to understand – this is a core requirement reflected in your prompt engineering.
* **Proactive Refinement:** While implementing, if you identify areas for improving clarity or efficiency (e.g., in prompt structuring, error handling), implement those improvements.
* **Robustness:** Anticipate potential issues, especially with external API calls (Gemini), image processing, and response parsing. Implement graceful error handling and provide informative feedback to the user.
* **Documentation Focus:** Clearly document your code, especially the prompt engineering logic, API interaction steps, and any non-obvious implementation details.

**3. Tech Stack**

* **LLM:** Google Gemini 2.5 Pro Experimental (`gemini-2.5-pro-exp-03-25`)
* **Backend:** Python 3.9+ with Flask
* **LLM SDK:** `google-generativeai` Python library
* **Frontend:** Vanilla HTML, CSS, JavaScript (ES6+)
* **API Communication:** Fetch API (JavaScript), JSON
* **Image Handling:**
    * Frontend: Browser `FileReader` API for reading and Base64 encoding.
    * Backend: Base64 decoding, potentially `Pillow` library if basic validation/manipulation is needed before sending to Gemini API (though aim to rely on Gemini's direct handling first).
* **State Management:** Simple JavaScript array on the frontend for session chat history.
* **Dependencies:** `Flask`, `python-dotenv`, `google-generativeai`, `Flask-Cors`, `Pillow` (optional, for backend image handling if needed).

**4. Error Fixing Process**

1.  **Identify the Source:** Is the error occurring in the Frontend (browser console) or Backend (Flask console/logs)?
2.  **Read the Full Error:** Understand the complete error message and traceback.
3.  **Check Common Issues:**
    * **Frontend:** CORS errors (check Flask-Cors setup), JavaScript syntax errors, DOM manipulation errors (element not found), incorrect `Workspace` API usage, Base64 encoding issues.
    * **Backend:** Python syntax errors, import errors, environment variable loading (`GOOGLE_API_KEY`), incorrect Gemini library usage, API key validity, Gemini API errors (rate limits, model access, content policy violations), Base64 decoding errors, JSON parsing failures (if Gemini response format deviates).
4.  **Validate Data Flow:** Log the data being passed at each step: user input -> frontend payload -> backend received data -> data sent to Gemini -> Gemini response -> parsed data -> data sent to frontend -> frontend display.
5.  **Isolate the Problem:** If it's an API issue, test the Gemini API call directly from the backend with sample data. If it's a frontend issue, simplify the JS logic temporarily.
6.  **Consult Documentation:** Refer to Flask, `google-generativeai`, and MDN Web Docs (for JS/HTML/CSS/Fetch).
7.  **Test Thoroughly:** Verify the fix resolves the issue without introducing regressions. Test with both text and image inputs.
8.  **Document:** Add comments explaining the fix if the logic isn't immediately obvious.

**5. Building Process (Sequential Flow)**

Follow a logical, layered approach:

1.  **Backend Foundation:**
    * Set up the Flask project structure (`backend` folder, `app.py`, `requirements.txt`, `.env`, `.gitignore`).
    * Implement secure loading of `GOOGLE_API_KEY` from `.env`.
    * Install dependencies.
2.  **Gemini Client Module (`gemini_client.py`):**
    * Implement `initialize_gemini` to configure the SDK and instantiate the `gemini-2.5-pro-exp-03-25` model.
    * Implement `generate_stem_response`:
        * Input handling (text, base64 image).
        * **CRITICAL:** Precise Prompt Construction (Role, Solve, Explain Simply, 2 Practice Qs, **Strict JSON Output Instruction**).
        * API call using `google-generativeai` library, passing text and/or image parts correctly.
        * Robust Response Parsing (Expect JSON, validate structure, handle API errors and JSON parsing errors gracefully).
3.  **Backend API Endpoint (`app.py`):**
    * Create the `/api/solve` POST endpoint.
    * Configure CORS using `Flask-Cors`.
    * Receive JSON payload (text/image data).
    * Validate input.
    * Call the `generate_stem_response` function.
    * Format and return the success JSON response or an appropriate error JSON response with status codes (200, 400, 500).
4.  **Frontend Structure (`index.html`, `style.css`):**
    * Create the HTML layout: chat history display, text input, image input/preview, submit button, loading indicator.
    * Apply basic CSS for usability and clear visual separation of elements (user query, bot response).
5.  **Frontend Logic (`script.js`):**
    * Get DOM references.
    * Implement client-side state management for chat history (JavaScript array).
    * Implement `renderChatHistory` function to display the array content in the DOM.
    * Implement image selection logic using `FileReader` to get Base64 data and update preview.
    * Implement `handleSubmit` function:
        * Get text/image inputs.
        * Perform basic frontend validation (ensure input exists).
        * Add user query to chat history and render.
        * Prepare payload for the backend API (ensure Base64 string is correctly formatted).
        * Show loading indicator.
        * Make the `Workspace` POST call to `/api/solve`.
        * Handle success: Parse response, format bot output (solution, explanation, practice Qs clearly), add to chat history, render, hide loading.
        * Handle errors: Display user-friendly error message in chat history, log technical details to console, hide loading.
        * Clear input fields.
6.  **Integration Testing:** Thoroughly test the end-to-end flow with various valid and invalid inputs (text, images, edge cases).

**6. Our `.env` Variables**

Create a `.env` file in the `backend` directory (ensure it's in `.gitignore`):

```
# Google AI Configuration
# --- IMPORTANT: Obtain your API key from Google AI Studio or GCP ---
# --- and ensure the key has access to the 'gemini-2.5-pro-exp-03-25' model ---
GOOGLE_API_KEY=YOUR_ACTUAL_GEMINI_API_KEY

# Flask Configuration (Optional - Flask defaults are often sufficient for dev)
# FLASK_ENV=development
```

**7. Target File Structure**

```
/stem-helper-chatbot/
├── backend/
│   ├── app.py              # Flask app, API endpoint
│   ├── gemini_client.py    # Gemini API interaction logic
│   ├── requirements.txt    # Python dependencies
│   ├── .env                # Environment variables (GITIGNORED!)
│   └── .gitignore          # Git ignore file
│
├── frontend/
│   ├── index.html          # Main HTML structure
│   ├── style.css           # CSS styling
│   └── script.js           # JavaScript logic (API calls, DOM manipulation)
│
└── README.md               # Project documentation (Agent should update this)
```

**8. Important Constraints & Features Recap**

* **Core Model:** Must use `gemini-2.5-pro-exp-03-25`.
* **Input:** Accept plain text OR an uploaded image per request.
* **Output:** For each valid request, MUST provide:
    1.  Step-by-step solution.
    2.  **Simple** explanation of concepts.
    3.  Two similar practice questions.
* **LLM Response Format:** Instruct Gemini to return output STRICTLY as a JSON object: `{"solution": "...", "explanation": "...", "practice_questions": ["...", "..."]}`. Robustly parse this JSON on the backend.
* **Chat History:** Maintain history ONLY for the current browser session (frontend JavaScript array). No persistence needed.
* **No Login/Users:** The application is anonymous and requires no user authentication or profiles.
* **Simplicity:** Prioritize ease of use for the student. Explanations must be genuinely simple.

**9. Other Context**

* This is a new build, not a migration.
* Focus on the core functionality; no need for advanced features beyond the scope defined.
* The application must run locally, requiring only Python, Node.js (for serving/dev tools if any), a browser, and the Gemini API key.
* Reliability of interaction with the *experimental* Gemini model is key; implement thorough error handling around the API call and response parsing.

**10. Comments & Documentation Standards**

* **Python:** Use docstrings for all functions, especially in `gemini_client.py` explaining parameters, return values, and potential errors. Comment complex logic blocks (e.g., prompt construction, specific error handling).
* **JavaScript:** Add comments explaining the purpose of functions, complex DOM manipulations, state management logic, and fetch API call/response handling.
* **README.md:** Generate or update a README file explaining what the project is, the tech stack, how to set it up (install dependencies, set API key in `.env`), and how to run it (start backend, serve frontend).

